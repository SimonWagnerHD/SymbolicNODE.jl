{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "using OrdinaryDiffEq, NODEData, Plots\n",
    "using Flux, DiffEqSensitivity, Parameters\n",
    "using Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function lorenz63(x,p,t)\n",
    "    σ, β, ρ = p \n",
    "    [σ*(x[2] - x[1]), x[1]*(ρ - x[3]) - x[2], x[1]*x[2] - β*x[3]]\n",
    "end\n",
    "\n",
    "σ = 10\n",
    "β = 8f0/3\n",
    "ρ = 28\n",
    "p = [σ, β, ρ]\n",
    "\n",
    "t_transient = 100\n",
    "N_t_train = 500\n",
    "N_t_valid = N_t_train*3\n",
    "N_t = N_t_train + N_t_valid\n",
    "dt = 0.1f0\n",
    "tspan = (0f0, Float32(t_transient + N_t * dt))\n",
    "\n",
    "x0 = [0.1f0, 0.1f0, 0.1f0] \n",
    "\n",
    "prob = ODEProblem(lorenz63, x0, tspan, p) \n",
    "sol = solve(prob, Tsit5(), saveat=saveat=t_transient:dt:t_transient + N_t * dt)\n",
    "\n",
    "t_train = t_transient:dt:t_transient+N_t_train*dt\n",
    "data_train = Array(sol(t_train))\n",
    "\n",
    "t_valid = t_transient+N_t_train*dt:dt:t_transient+N_t_train*dt+N_t_valid*dt\n",
    "data_valid = Array(sol(t_valid))\n",
    "\n",
    "train = NODEDataloader(Float32.(data_train), t_train, 2)\n",
    "valid = NODEDataloader(Float32.(data_valid), t_valid, 2)\n",
    "\n",
    "#train, valid = NODEDataloader(sol, 10; dt=dt, valid_set=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot3d(sol[1,:], sol[2,:], sol[3,:], camera = (45 , 40), xlabel=\"x\", ylabel=\"y\", zlabel=\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define ANN\n",
    "N_WEIGHTS = 16 \n",
    "nn = Chain(Dense(3, N_WEIGHTS, relu), Dense(N_WEIGHTS, N_WEIGHTS, relu), Dense(N_WEIGHTS, N_WEIGHTS, relu), Dense(N_WEIGHTS, N_WEIGHTS, relu), Dense(N_WEIGHTS, 3))\n",
    "p, re_nn = Flux.destructure(nn)\n",
    "\n",
    "\n",
    "function neural_lorenz63(u, p, t)\n",
    "    σ = 10\n",
    "    β = 8f0/3\n",
    "    [σ*(x[2] - x[1]), re_nn(p) - x[2], x[1]*x[2] - β*x[3]]\n",
    "end\n",
    "\n",
    "neural_ode(u, p, t) = re_nn(p)(u)\n",
    "node_prob = ODEProblem(neural_ode, x0, (Float32(0.),Float32(dt)), p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract type AbstractChaoticNDEModel end \n",
    "\n",
    "\"\"\"\n",
    "    ChaoticNDE{P,R,A,K} <: AbstractChaoticNDEModel\n",
    "\n",
    "Model for setting up and training Chaotic Neural Differential Equations.\n",
    "\n",
    "# Fields:\n",
    "\n",
    "* `p` parameter vector \n",
    "* `prob` DEProblem \n",
    "* `alg` Algorithm to use for the `solve` command \n",
    "* `kwargs` any additional keyword arguments that should be handed over (e.g. `sensealg`)\n",
    "\n",
    "# Constructor \n",
    "\n",
    "`ChaoticNDE(prob; alg=Tsit5(), kwargs...)`\n",
    "\"\"\"\n",
    "struct ChaoticNDE{P,R,A,K} <: AbstractChaoticNDEModel\n",
    "    p::P \n",
    "    prob::R \n",
    "    alg::A\n",
    "    kwargs::K\n",
    "end \n",
    "\n",
    "function ChaoticNDE(prob; alg=Tsit5(), kwargs...)\n",
    "    p = prob.p \n",
    "    ChaoticNDE{typeof(p), typeof(prob), typeof(alg), typeof(kwargs)}(p, prob, alg, kwargs)\n",
    "end \n",
    "\n",
    "Flux.@functor ChaoticNDE\n",
    "Flux.trainable(m::ChaoticNDE) = (p=m.p,)\n",
    "\n",
    "function (m::ChaoticNDE)(X,p=m.p)\n",
    "    (t, x) = X \n",
    "    Array(solve(remake(m.prob; tspan=(t[1],t[end]),u0=x[:,1],p=p), m.alg; saveat=t, m.kwargs...))\n",
    "end\n",
    "\n",
    "model = ChaoticNDE(node_prob)\n",
    "model(train[1])\n",
    "\n",
    "loss(x, y) = sum(abs2, x - y)\n",
    "loss(model(train[1]), train[1][2]) \n",
    "\n",
    "η = 1f-3\n",
    "opt = Flux.AdamW(η)\n",
    "opt_state = Flux.setup(opt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "#η = 1f-3\n",
    "\n",
    "loss_log = Float32[]\n",
    "for epoch in 1:30\n",
    "    if (epoch % 5) == 0 println(\"Epoch:\", epoch) end\n",
    "    losses = Float32[]\n",
    "    for (i, data) in enumerate(train)\n",
    "        t, x = data\n",
    "\n",
    "        val, grads = Flux.withgradient(model) do m\n",
    "            # Any code inside here is differentiated.\n",
    "            # Evaluation of the model and loss must be inside!\n",
    "            result = m((t,x))\n",
    "            loss(result, x)\n",
    "        end\n",
    "\n",
    "        # Save the loss from the forward pass. (Done outside of gradient.)\n",
    "        push!(losses, val)\n",
    "\n",
    "        # Detect loss of Inf or NaN. Print a warning, and then skip update!\n",
    "        if !isfinite(val)\n",
    "            @warn \"loss is $val on item $i\" epoch\n",
    "            continue\n",
    "        end\n",
    "\n",
    "    Flux.update!(opt_state, model, grads[1])\n",
    "    end\n",
    "    push!(loss_log, Statistics.mean(losses))\n",
    "\n",
    "    if (epoch % 30) == 0  # reduce the learning rate every 30 epochs\n",
    "        η /= 2\n",
    "        Flux.adjust!(opt_state, η)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test model\n",
    "t = convert(Array{Float32,1}, collect(0:0.1:2))\n",
    "rec_sol = model((t,x0))\n",
    "plot3d(rec_sol[1,:], rec_sol[2,:], rec_sol[3,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
